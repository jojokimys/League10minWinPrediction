# -*- coding: utf-8 -*-
"""League10minWinPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gpKHAXsWSswkTX9NWhskg4x_ZELY4_ns
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/content/'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#import libraries
import matplotlib.pyplot as plt
import seaborn as sns

"""# Import Data
Data I will be using for this project is "high_diamond_ranked_10min.csv"
from https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min

It contains columns of "blueWins" which is my target variable, and other variables such as "blueKills" or "blueTotalGold", and I will be trying to figure out what components are most important in winning a game of league during first 10 minutes of the game.
Also, I will be comparing accuracy of following algorithms. 
["Logistic Regression", "Decision Tree Classification", "XGBoost", "Neural Network (Keras)", "Neural Network (Pytorch)"]
"""

# import data
url = '/content/high_diamond_ranked_10min.csv'

data = pd.read_csv(url, index_col=0)
data.head()

# data types are mostly int64, and some are float64
data.info()

# no NULL values exist in the dataset
data.isna().values.any()

# Check histogram to see if data is normally distributed.
data.hist(bins = 50, figsize = (20,40))
plt.show()

"""Most of data is normally distributed so now I'm ready to pre process the data."""

# check heatmap for correlations
import seaborn as sns
plt.figure(figsize=(16, 12))
temp = data.copy()
sns.heatmap(temp.drop('blueWins', axis=1).corr(), annot=True);

# find highly correlated values with correlation over 0.9
corr = pd.DataFrame(temp.corr().unstack().sort_values().drop_duplicates())
corr.columns = ['cr']
corr[(corr['cr'] > 0.9) | (corr['cr'] < -0.9)]

"""# Preparing Data"""

# Drop highly correlated values and reformat data.
df = data.copy()

df['ExperienceDiff'] = df['blueExperienceDiff']
df['blueWardScore'] = df['blueWardsPlaced'] + df['blueWardsDestroyed']
df['redWardScore'] = df['redWardsPlaced'] + df['redWardsDestroyed']

df = df.drop(columns=['blueWardsPlaced', 'blueWardsDestroyed', 'redWardsPlaced', 'redWardsDestroyed'])
df = df.drop(columns=['blueExperienceDiff', 'redExperienceDiff', 'blueTotalMinionsKilled', 'redTotalMinionsKilled', 'blueGoldPerMin','redGoldPerMin', 'blueAvgLevel','redAvgLevel'])
df = df.drop(columns=['blueFirstBlood', 'redFirstBlood'])
df.head()

"""# Machine Learning Algorithms"""

# create trainset and test set
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import cross_val_score

# X is variables, y is the target "blueWins"
X = df.drop('blueWins', axis = 1)
y = df['blueWins']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)
X_scaled = preprocessing.scale(X_train)

"""## Logistic Regression"""

# train
from sklearn.linear_model import LogisticRegression
Logreg = LogisticRegression(random_state = 1)
scores = cross_val_score(Logreg, X_scaled, y_train, scoring = 'accuracy', cv = 10)
meanScore = scores.mean()

print("Logistic Regression model has Accuracy of", meanScore)

"""## Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
decisionTree = DecisionTreeClassifier(max_depth = 2, random_state = 3)

scores = cross_val_score(decisionTree, X_scaled, y_train, scoring = 'accuracy', cv = 10)
meanScore = scores.mean()
print("Decision Tree model has Accuracy of", meanScore)

#  plot decision tree
from sklearn import tree
decisionTree.fit(X_train, y_train)
decisionTree.predict(X_test)
tree.plot_tree(decisionTree);

"""## XGBoost"""

from xgboost import XGBClassifier

xgb = XGBClassifier(n_estimators = 100 ,learning_rate = 0.1)

scores = cross_val_score(xgb, X_scaled, y_train, scoring = 'accuracy', cv = 10)
meanScore = scores.mean()
print("XGBoost model has Accuracy of", meanScore)

# Displaying Feature Importance
from matplotlib import pyplot

xgb.fit(X_train, y_train)

fi = xgb.feature_importances_
pyplot.bar(range(len(fi)), fi)
for i, item in enumerate(X_train.columns.values):
  print(f'[{i}] {item} has feature importance of {fi[i]}')
pyplot.show()

"""## Neural Network (Keras)"""

# import libraries
from tensorflow.keras.layers import Activation, Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import optimizers
from tensorflow import keras
from keras.models import Model

k_df = df;
y=data['blueWins'] 
k_df.drop(['blueWins'],1,inplace=True)
k_df

# Normalize Z-Score
mean = k_df.mean(axis=0)
std = k_df.std(axis=0)
n_df = (k_df-mean)/std
n_df.head()

model = Sequential()
model.add(Dense(32, input_shape=(27,)))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

opt = optimizers.Adam(learning_rate=0.005)
model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])

history = model.fit(k_df, y, batch_size=100, epochs=4, validation_split=0.2)

"""## Neural Network (Pytorch)"""

# import libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset, random_split

# get data
targets = data[['blueWins']].values
features = df.values

test_size = int(.10 * 9879) 
val_size = test_size
train_size = 9879 - test_size*2
train_size , val_size, test_size


dataset = TensorDataset(torch.tensor(features).float(), torch.from_numpy(targets).float())
pt_train, val_df, test_df = random_split(dataset, [train_size, val_size, test_size])

# train
input_size = 27 
output_size = 1 
threshold = 0.5
batch_size = 128

train_loader = DataLoader(pt_train, batch_size, shuffle=True)
val_loader = DataLoader(val_df, batch_size)
test_loader = DataLoader(test_df, batch_size)

class PTModel(nn.Module):
    def __init__(self):
        # initiate the model
        super().__init__()
        self.linear = nn.Linear(input_size, output_size)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, xb):
        # forward function of the model 
        out = self.sigmoid(self.linear(xb))
        return out
    
    def training_step(self, batch):
        # used for training per batch in an eopch
        inputs, labels = batch
        out = self(inputs)
        loss = F.binary_cross_entropy(out, labels)
        return loss
    
    def validation_step(self, batch):
        # used on function `evaluate` to iterate model through a batch
        inputs, labels = batch
        out = self(inputs)
        loss = F.binary_cross_entropy(out, labels)
        acc = accuracy(out, labels)
        # `.detach()` makes sure gradient is not tracked
        return {'val_loss': loss.detach(), 'val_acc' : acc.detach()}
    
    def validation_epoch_end(self, outputs):
        # calculate mean loss and accuracy for batch called w/ `evaluate`
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()
        return {'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()}
    
    def epoch_end(self, epoch, result, num_epochs):
        # print function to see what's going on
        if ((epoch+1) % 10 == 0) or (epoch == (num_epochs-1)):
            # print for every 5 epochs
            print("Epoch [{}], val_loss: {:.4f}, val_acc {:.4f}".format(epoch+1, result['val_loss'], result['val_acc']))

def accuracy(out, labels):
    return torch.tensor(torch.sum(abs(out-labels) < threshold).item() / len(out))

def evaluate(model, val_loader):
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):
    history = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training Phase 
        for batch in train_loader:
            loss = model.training_step(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        model.epoch_end(epoch, result, epochs)
        history.append(result)
    return history

model = PTModel()

evaluate(model, val_loader)

history = fit(750, .0001, model, train_loader, val_loader)

accuracies = [r['val_acc'] for r in history]
plt.plot(accuracies, '-x')
plt.xlabel('epoch')
plt.ylabel('Accuracy')
plt.title('Accuracy vs. No. of epochs')

evaluate(model, test_loader)

"""# Conclusion

After trying 5 different Algorithms
we got the results of


*   Logistic Regression : 0.7316215653955097
*   Decision Tree : 0.7258005408951976
*   XGBoost : 0.728458448686969
*   Neural Network (Keras) : 0.6430
*   Neural Network (Pytorch) : 0.6933808326721191
"""